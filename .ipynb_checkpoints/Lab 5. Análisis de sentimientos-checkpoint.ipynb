{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a684c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import re\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d473a4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfil_sentimientos(df):\n",
    "    print(target)\n",
    "    print(\"=\" * 12)\n",
    "    print(f\"Positivos: {round(100 * np.mean(df.sentimiento >= 0), 2)}\")\n",
    "    print(f\"Negativos: {round(100 * np.mean(df.sentimiento < 0), 2)}\")\n",
    "    print(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2855e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_tokenizar(texto):\n",
    "    '''\n",
    "    Esta función limpia y tokeniza el texto en palabras individuales.\n",
    "    El orden en el que se va limpiando el texto no es arbitrario.\n",
    "    El listado de signos de puntuación se ha obtenido de: print(string.punctuation)\n",
    "    y re.escape(string.punctuation)\n",
    "    '''\n",
    "    \n",
    "    # Se convierte todo el texto a minúsculas\n",
    "    nuevo_texto = texto.lower()\n",
    "    # Eliminación de páginas web (palabras que empiezan por \"http\")\n",
    "    nuevo_texto = re.sub('http\\S+', ' ', nuevo_texto)\n",
    "    # Eliminación de signos de puntuación\n",
    "    regex = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
    "    nuevo_texto = re.sub(regex , ' ', nuevo_texto)\n",
    "    # Eliminación de números\n",
    "    nuevo_texto = re.sub(\"\\d+\", ' ', nuevo_texto)\n",
    "    # Eliminación de espacios en blanco múltiples\n",
    "    nuevo_texto = re.sub(\"\\\\s+\", ' ', nuevo_texto)\n",
    "    # Tokenización por palabras individuales\n",
    "    nuevo_texto = nuevo_texto.split(sep = ' ')\n",
    "    # Eliminación de tokens con una longitud < 2\n",
    "    nuevo_texto = [token for token in nuevo_texto if len(token) > 1]\n",
    "    \n",
    "    return(nuevo_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1777ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminaremos los artículos, proposiciones (stopwords) y otras palabras que no aportan un valor conceptual en nuestros tweets\n",
    "\n",
    "def limpiar_tokenizar(texto):\n",
    "    '''\n",
    "    Esta función limpia y tokeniza el texto en palabras individuales.\n",
    "    El orden en el que se va limpiando el texto no es arbitrario.\n",
    "    El listado de signos de puntuación se ha obtenido de: print(string.punctuation)\n",
    "    y re.escape(string.punctuation)\n",
    "    '''\n",
    "    \n",
    "    # Se convierte todo el texto a minúsculas\n",
    "    nuevo_texto = texto.lower()\n",
    "    # Eliminación de páginas web (palabras que empiezan por \"http\")\n",
    "    nuevo_texto = re.sub('http\\S+', ' ', nuevo_texto)\n",
    "    # Eliminación de signos de puntuación\n",
    "    regex = '[\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\<\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~]'\n",
    "    nuevo_texto = re.sub(regex , ' ', nuevo_texto)\n",
    "    # Eliminación de números\n",
    "    nuevo_texto = re.sub(\"\\d+\", ' ', nuevo_texto)\n",
    "    # Eliminación de espacios en blanco múltiples\n",
    "    nuevo_texto = re.sub(\"\\\\s+\", ' ', nuevo_texto)\n",
    "    # Tokenización por palabras individuales\n",
    "    nuevo_texto = nuevo_texto.split(sep = ' ')\n",
    "    # Eliminación de tokens con una longitud < 2\n",
    "    nuevo_texto = [token for token in nuevo_texto if len(token) > 1]\n",
    "    \n",
    "    return(nuevo_texto)\n",
    "\n",
    "\n",
    "# Eliminando las stopwords de inglés\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8ccb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eragr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753b887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()\n",
    "\n",
    "True\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer('\\s+', gaps=True)\n",
    "\n",
    "tokenizer.tokenize(\"As-Salam-o-Alikum Sir, the name of the tutorial is \\ Installation of NLTK package and downloading of NLTK \\ corpus on Python\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a74cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7dccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484488c",
   "metadata": {},
   "source": [
    "### 3. Limpieza y procesamiento del los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06691ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>texto_tokenizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                   texto_tokenizado  \n",
       "0       1  [our, deeds, are, the, reason, of, this, earth...  \n",
       "1       1      [forest, fire, near, la, ronge, sask, canada]  \n",
       "2       1  [all, residents, asked, to, shelter, in, place...  \n",
       "3       1  [people, receive, wildfires, evacuation, order...  \n",
       "4       1  [just, got, sent, this, photo, from, ruby, ala...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizamos la limpieza para cada uno de los tweets\n",
    "\n",
    "train['texto_tokenizado'] = train['text'].apply(lambda x: limpiar_tokenizar(x))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd09b99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  target   token\n",
       "0   1     NaN      NaN       1     our\n",
       "0   1     NaN      NaN       1   deeds\n",
       "0   1     NaN      NaN       1     are\n",
       "0   1     NaN      NaN       1     the\n",
       "0   1     NaN      NaN       1  reason"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora por cada token se tendra una fila (con mismo id, keyword, location y target), con el objetivo de facilitar \n",
    "# la exploración de data\n",
    "\n",
    "# Unnest de la columna texto_tokenizado\n",
    "# ==============================================================================\n",
    "tweets_tidy = train.explode(column='texto_tokenizado')\n",
    "tweets_tidy = tweets_tidy.drop(columns='text')\n",
    "tweets_tidy = tweets_tidy.rename(columns={'texto_tokenizado':'token'})\n",
    "tweets_tidy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24775d91",
   "metadata": {},
   "source": [
    "### 4. Frecuencia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab482b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Palabras por real desastre (1) o no (0) \n",
      "--------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    57628\n",
       "1    44380\n",
       "Name: token, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total de palabras utilizadas en tweets de desastre y no desastre\n",
    "# ==============================================================================\n",
    "print('--------------------------')\n",
    "print('Palabras por real desastre (1) o no (0) ')\n",
    "print('--------------------------')\n",
    "tweets_tidy.groupby(by='target')['token'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233f48d",
   "metadata": {},
   "source": [
    "Se tienen 13 mil palabras más provenientes de tweets con desastres reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d784d",
   "metadata": {},
   "source": [
    "#### Palabras más utilizadas en tweets desastres reales o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "087d5994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>10394</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>1914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10583</th>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>1191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0</td>\n",
       "      <td>and</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7282</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>19486</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>1363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15655</th>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17241</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19627</th>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12168</th>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              target token  count\n",
       "target                           \n",
       "0      10394       0   the   1914\n",
       "       10583       0    to   1191\n",
       "       351         0   and    919\n",
       "       7282        0    of    902\n",
       "       5084        0    in    822\n",
       "1      19486       1   the   1363\n",
       "       15655       1    in   1162\n",
       "       17241       1    of    923\n",
       "       19627       1    to    757\n",
       "       12168       1   and    505"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontramos las 10 palabras más utilizadas en los tipos de tweets\n",
    "\n",
    "tweets_tidy.groupby(['target','token'])['token'] \\\n",
    " .count() \\\n",
    " .reset_index(name='count') \\\n",
    " .groupby('target') \\\n",
    " .apply(lambda x: x.sort_values('count', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd25f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encontramos el listado de stopwords en inglés\n",
    "stop_words = list(stopwords.words('english'))\n",
    "# Se añade la stoprword: amp, ax, ex\n",
    "stop_words.extend((\"amp\", \"xa\", \"xe\"))\n",
    "print(stop_words[:10])\n",
    "\n",
    "# Filtrado para excluir stopwords\n",
    "# ==============================================================================\n",
    "tweets_tidy = tweets_tidy[~(tweets_tidy[\"token\"].isin(stop_words))]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1,figsize=(6, 7))\n",
    "for i, target in enumerate(tweets_tidy.target.unique()):\n",
    "    df_temp = tweets_tidy[tweets_tidy.target == target]\n",
    "    counts  = df_temp['token'].value_counts(ascending=False).head(10)\n",
    "    counts.plot(kind='barh', color='firebrick', ax=axs[i])\n",
    "    axs[i].invert_yaxis()\n",
    "    axs[i].set_title(target)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03b125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c58c647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16972</th>\n",
       "      <td>2793</td>\n",
       "      <td>aka</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16990</th>\n",
       "      <td>2793</td>\n",
       "      <td>tlk</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16989</th>\n",
       "      <td>2793</td>\n",
       "      <td>steal</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  token  count  total_count        tf\n",
       "16972  2793    aka      1           23  0.043478\n",
       "16990  2793    tlk      1           23  0.043478\n",
       "16989  2793  steal      1           23  0.043478"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cálculo term-frecuency (tf)\n",
    "# ==============================================================================\n",
    "tf = tweets_tidy.copy()\n",
    "# Número de veces que aparece cada término en cada tweet\n",
    "tf = tf.groupby([\"id\", \"token\"])[\"token\"].agg([\"count\"]).reset_index()\n",
    "# Se añade una columna con el total de términos por tweet\n",
    "tf['total_count'] = tf.groupby('id')['count'].transform(sum)\n",
    "# Se calcula el tf\n",
    "tf['tf'] = tf[\"count\"] / tf[\"total_count\"]\n",
    "tf.sort_values(by = \"tf\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0ee079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>n_documentos</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33470</th>\n",
       "      <td>like</td>\n",
       "      <td>348</td>\n",
       "      <td>3.085410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21139</th>\n",
       "      <td>fire</td>\n",
       "      <td>252</td>\n",
       "      <td>3.408184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23766</th>\n",
       "      <td>get</td>\n",
       "      <td>229</td>\n",
       "      <td>3.503891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      token  n_documentos       idf\n",
       "33470  like           348  3.085410\n",
       "21139  fire           252  3.408184\n",
       "23766   get           229  3.503891"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse document frequency\n",
    "# ==============================================================================\n",
    "idf = tweets_tidy.copy()\n",
    "total_documents = idf[\"id\"].drop_duplicates().count()\n",
    "# Número de documentos (tweets) en los que aparece cada término\n",
    "idf = idf.groupby([\"token\", \"id\"])[\"token\"].agg([\"count\"]).reset_index()\n",
    "idf['n_documentos'] = idf.groupby('token')['count'].transform(sum)\n",
    "# Cálculo del idf\n",
    "idf['idf'] = np.log(total_documents / idf['n_documentos'])\n",
    "idf = idf[[\"token\",\"n_documentos\", \"idf\"]].drop_duplicates()\n",
    "idf.sort_values(by=\"idf\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae40c9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>tf</th>\n",
       "      <th>n_documentos</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>allah</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>9</td>\n",
       "      <td>6.740388</td>\n",
       "      <td>0.962913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>reason</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>20</td>\n",
       "      <td>5.941880</td>\n",
       "      <td>0.848840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1</td>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>128</td>\n",
       "      <td>4.085582</td>\n",
       "      <td>0.583655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>may</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>89</td>\n",
       "      <td>4.448976</td>\n",
       "      <td>0.635568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>50</td>\n",
       "      <td>5.025590</td>\n",
       "      <td>0.717941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       token  count  total_count        tf  n_documentos       idf  \\\n",
       "0     1       allah      1            7  0.142857             9  6.740388   \n",
       "144   1      reason      1            7  0.142857            20  5.941880   \n",
       "164   1          us      1            7  0.142857           128  4.085582   \n",
       "57    1         may      1            7  0.142857            89  4.448976   \n",
       "11    1  earthquake      1            7  0.142857            50  5.025590   \n",
       "\n",
       "       tf_idf  \n",
       "0    0.962913  \n",
       "144  0.848840  \n",
       "164  0.583655  \n",
       "57   0.635568  \n",
       "11   0.717941  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term Frequency - Inverse Document Frequency\n",
    "# ==============================================================================\n",
    "tf_idf = pd.merge(left=tf, right=idf, on=\"token\")\n",
    "tf_idf[\"tf_idf\"] = tf_idf[\"tf\"] * tf_idf[\"idf\"]\n",
    "tf_idf.sort_values(by=\"id\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ca24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8836d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparto train y test\n",
    "# ==============================================================================\n",
    "datos_X = train.loc[train.target.isin([0, 1]), 'text']\n",
    "datos_y = train.loc[train.target.isin([0, 1]), 'target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    datos_X,\n",
    "    datos_y,\n",
    "    test_size = 0.2,\n",
    "    random_state = 123\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f99dafc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 56.86371100164204, 1: 43.13628899835796}\n",
      "{0: 57.715036112934996, 1: 42.284963887065004}\n"
     ]
    }
   ],
   "source": [
    "value, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(value, 100 * counts / sum(counts))))\n",
    "value, counts = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(value, 100 * counts / sum(counts))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9393ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eragr\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=3,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                tokenizer=<function limpiar_tokenizar at 0x000001676CDE81F0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "# Se añade la stopword: amp, ax, ex\n",
    "stop_words.extend((\"amp\", \"xa\", \"xe\"))\n",
    "# Creación de la matriz tf-idf\n",
    "# ==============================================================================\n",
    "tfidf_vectorizador = TfidfVectorizer(\n",
    "                        tokenizer  = limpiar_tokenizar,\n",
    "                        min_df     = 3,\n",
    "                        stop_words = stop_words\n",
    "                    )\n",
    "tfidf_vectorizador.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3d1470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Número de tokens creados: 3616\n",
      "['aba', 'abandoned', 'abbswinston', 'abc', 'abcnews', 'abe', 'ability', 'ablaze', 'able', 'abortion']\n"
     ]
    }
   ],
   "source": [
    "tfidf_train = tfidf_vectorizador.transform(X_train)\n",
    "tfidf_test  = tfidf_vectorizador.transform(X_test)\n",
    "print(f\" Número de tokens creados: {len(tfidf_vectorizador.get_feature_names())}\")\n",
    "print(tfidf_vectorizador.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c51e6",
   "metadata": {},
   "source": [
    "# Modelo SVM lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51a6a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.278256</td>\n",
       "      <td>0.790148</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.848153</td>\n",
       "      <td>0.004046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.779146</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>0.920936</td>\n",
       "      <td>0.002464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.681005</td>\n",
       "      <td>0.730870</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>0.971511</td>\n",
       "      <td>0.001193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>129.154967</td>\n",
       "      <td>0.714778</td>\n",
       "      <td>0.017575</td>\n",
       "      <td>0.984442</td>\n",
       "      <td>0.000353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.020679</td>\n",
       "      <td>0.985591</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035938</td>\n",
       "      <td>0.578161</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.001659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.568637</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.568637</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.568637</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.568637</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.568637</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.568637</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.568637</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.568637</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      param_C  mean_test_score  std_test_score  mean_train_score  \\\n",
       "5    0.278256         0.790148        0.011071          0.848153   \n",
       "6    2.154435         0.779146        0.013461          0.920936   \n",
       "7   16.681005         0.730870        0.013654          0.971511   \n",
       "8  129.154967         0.714778        0.017575          0.984442   \n",
       "9      1000.0         0.712644        0.020679          0.985591   \n",
       "4    0.035938         0.578161        0.002668          0.578571   \n",
       "0     0.00001         0.568637        0.000402          0.568637   \n",
       "1    0.000077         0.568637        0.000402          0.568637   \n",
       "2    0.000599         0.568637        0.000402          0.568637   \n",
       "3    0.004642         0.568637        0.000402          0.568637   \n",
       "\n",
       "   std_train_score  \n",
       "5         0.004046  \n",
       "6         0.002464  \n",
       "7         0.001193  \n",
       "8         0.000353  \n",
       "9         0.000239  \n",
       "4         0.001659  \n",
       "0         0.000101  \n",
       "1         0.000101  \n",
       "2         0.000101  \n",
       "3         0.000101  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento del modelo SVM\n",
    "# ==============================================================================\n",
    "modelo_svm_lineal = svm.SVC(kernel= \"linear\", C = 1.0)\n",
    "modelo_svm_lineal.fit(X=tfidf_train, y= y_train)\n",
    "\n",
    "# Grid de hiperparámetros\n",
    "# ==============================================================================\n",
    "param_grid = {'C': np.logspace(-5, 3, 10)}\n",
    "\n",
    "# Búsqueda por validación cruzada\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(\n",
    "        estimator  = svm.SVC(kernel= \"linear\"),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'accuracy',\n",
    "        n_jobs     = -2,\n",
    "        cv         = 5, \n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "      )\n",
    "\n",
    "# Se asigna el resultado a _ para que no se imprima por pantalla\n",
    "_ = grid.fit(X = tfidf_train, y = y_train)\n",
    "\n",
    "# Resultados del grid\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)')\\\n",
    "    .drop(columns = 'params')\\\n",
    "    .sort_values('mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6d3be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Mejores hiperparámetros encontrados (cv)\n",
      "----------------------------------------\n",
      "{'C': 0.2782559402207126} : 0.7901477832512315 accuracy\n"
     ]
    }
   ],
   "source": [
    "# Mejores hiperparámetros por validación cruzada\n",
    "# ==============================================================================\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Mejores hiperparámetros encontrados (cv)\")\n",
    "print(\"----------------------------------------\")\n",
    "print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "\n",
    "modelo_final = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f685c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Error de test\n",
      "-------------\n",
      "Número de clasificaciones erróneas de un total de 1523 clasificaciones: 302\n",
      "% de error: 19.829284307288248\n",
      "\n",
      "-------------------\n",
      "Matriz de confusión\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>817</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  817   62\n",
       "1  240  404"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error predicciones test\n",
    "# ==============================================================================\n",
    "predicciones_test = modelo_final.predict(X=tfidf_test)\n",
    "\n",
    "print(\"-------------\")\n",
    "print(\"Error de test\")\n",
    "print(\"-------------\")\n",
    "\n",
    "print(f\"Número de clasificaciones erróneas de un total de {tfidf_test.shape[0]} \" \\\n",
    "      f\"clasificaciones: {(y_test != predicciones_test).sum()}\"\n",
    ")\n",
    "print(f\"% de error: {100*(y_test != predicciones_test).mean()}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"-------------------\")\n",
    "print(\"Matriz de confusión\")\n",
    "print(\"-------------------\")\n",
    "pd.DataFrame(confusion_matrix(y_true = y_test, y_pred= predicciones_test),\n",
    "             columns= [0, 1],\n",
    "             index = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e199e3",
   "metadata": {},
   "source": [
    "# Analisis sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a93b5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>termino</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abandon</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandons</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abducted</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abduction</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     termino  sentimiento\n",
       "0    abandon           -2\n",
       "1  abandoned           -2\n",
       "2   abandons           -2\n",
       "3   abducted           -2\n",
       "4  abduction           -2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descarga lexicon sentimientos\n",
    "# ==============================================================================\n",
    "lexicon = pd.read_table(\n",
    "            'https://raw.githubusercontent.com/fnielsen/afinn/master/afinn/data/AFINN-en-165.txt',\n",
    "            names = ['termino', 'sentimiento']\n",
    "          )\n",
    "lexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6412817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentimiento promedio de cada tweet\n",
    "# ==============================================================================\n",
    "tweets_sentimientos = pd.merge(\n",
    "                            left     = tweets_tidy,\n",
    "                            right    = lexicon,\n",
    "                            left_on  = \"token\", \n",
    "                            right_on = \"termino\",\n",
    "                            how      = \"inner\"\n",
    "                      )\n",
    "tweets_sentimientos = tweets_sentimientos.drop(columns = \"termino\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d1e6440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  id  sentimiento\n",
       "0       0  24            3\n",
       "1       0  25            3\n",
       "2       0  31           -3\n",
       "3       0  32            1\n",
       "4       0  33            3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Se suman los sentimientos de las palabras que forman cada tweet.\n",
    "tweets_sentimientos = tweets_sentimientos[[\"target\", \"id\", \"sentimiento\"]] \\\n",
    "                      .groupby([\"target\", \"id\"])\\\n",
    "                      .sum().reset_index()\n",
    "tweets_sentimientos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "556397e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "============\n",
      "Positivos: 43.77\n",
      "Negativos: 56.23\n",
      " \n",
      "1\n",
      "============\n",
      "Positivos: 21.22\n",
      "Negativos: 78.78\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for target, df in tweets_sentimientos.groupby(\"target\"):\n",
    "    perfil_sentimientos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b111aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
